<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gemini Live Korean-English Translator</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&family=Noto+Sans+KR:wght@400;500;700&display=swap" rel="stylesheet">
    <style>
        body { font-family: 'Inter', sans-serif; }
        .kr-font { font-family: 'Noto Sans KR', sans-serif; }
        
        /* Custom Scrollbar */
        ::-webkit-scrollbar { width: 8px; }
        ::-webkit-scrollbar-track { background: #f1f1f1; }
        ::-webkit-scrollbar-thumb { background: #c1c1c1; border-radius: 4px; }
        ::-webkit-scrollbar-thumb:hover { background: #a8a8a8; }

        .glass-panel {
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(229, 231, 235, 0.5);
        }

        /* Animation for recording indicator */
        @keyframes pulse-red {
            0% { transform: scale(0.95); box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7); }
            70% { transform: scale(1); box-shadow: 0 0 0 10px rgba(239, 68, 68, 0); }
            100% { transform: scale(0.95); box-shadow: 0 0 0 0 rgba(239, 68, 68, 0); }
        }
        .recording-pulse { animation: pulse-red 2s infinite; }
    </style>
</head>
<body class="bg-gradient-to-br from-indigo-50 to-blue-100 h-screen flex flex-col overflow-hidden">

    <!-- Header -->
    <header class="bg-white shadow-sm z-10">
        <div class="max-w-7xl mx-auto px-4 py-3 flex justify-between items-center">
            <div class="flex items-center gap-3">
                <div class="bg-blue-600 text-white p-2 rounded-lg">
                    <i class="fa-solid fa-language text-xl"></i>
                </div>
                <div>
                    <h1 class="font-bold text-gray-800 text-lg">Gemini Live Captions</h1>
                    <p class="text-xs text-gray-500">Korean to English • System Audio + Mic</p>
                </div>
            </div>
            
            <div class="flex items-center gap-3">
                <div id="status-badge" class="px-3 py-1 rounded-full text-xs font-medium bg-gray-200 text-gray-600 flex items-center gap-2">
                    <div class="w-2 h-2 rounded-full bg-gray-400"></div>
                    Ready
                </div>
                <button id="btn-settings" class="p-2 text-gray-600 hover:bg-gray-100 rounded-full transition-colors" title="Settings">
                    <i class="fa-solid fa-cog text-lg"></i>
                </button>
                <button id="btn-pip" class="p-2 text-blue-600 hover:bg-blue-50 rounded-full transition-colors" title="Pop-out Subtitle Mode">
                    <i class="fa-solid fa-arrow-up-right-from-square text-lg"></i>
                </button>
            </div>
        </div>
    </header>

    <!-- Main Content -->
    <main class="flex-1 flex flex-col max-w-5xl mx-auto w-full p-4 gap-4 h-full relative">
        
        <!-- API Key Input (Overlay if not set) -->
        <div id="api-key-modal" class="absolute inset-0 z-50 flex items-center justify-center bg-white/80 backdrop-blur-sm">
            <div class="bg-white p-6 rounded-2xl shadow-xl w-full max-w-md border border-gray-200">
                <h2 class="text-xl font-bold mb-4 text-gray-800">Setup Gemini API</h2>
                <p class="text-sm text-gray-600 mb-4">To enable high-accuracy audio translation, please enter your Gemini API key.</p>
                <input type="password" id="api-key-input" placeholder="Paste API Key here (starts with AIza...)" 
                    class="w-full p-3 border border-gray-300 rounded-lg mb-4 focus:ring-2 focus:ring-blue-500 outline-none">
                <button id="btn-save-key" class="w-full bg-blue-600 hover:bg-blue-700 text-white font-medium py-2 rounded-lg transition">
                    Start Translator
                </button>
                <p class="text-xs text-gray-400 mt-2 text-center">Your key is stored locally in your browser only.</p>
            </div>
        </div>

        <!-- Controls -->
        <div class="flex justify-center mb-2">
            <button id="btn-start" class="group relative inline-flex items-center justify-center px-8 py-3 text-base font-medium text-white bg-blue-600 rounded-full hover:bg-blue-700 transition-all shadow-lg hover:shadow-xl transform hover:-translate-y-0.5">
                <span class="mr-2"><i class="fa-solid fa-microphone"></i></span>
                Start Capture
                <span class="absolute -top-1 -right-1 flex h-3 w-3">
                    <span class="animate-ping absolute inline-flex h-full w-full rounded-full bg-blue-400 opacity-75"></span>
                    <span class="relative inline-flex rounded-full h-3 w-3 bg-blue-500"></span>
                </span>
            </button>
            <button id="btn-stop" class="hidden px-8 py-3 text-base font-medium text-white bg-red-500 rounded-full hover:bg-red-600 transition-all shadow-lg">
                <span class="mr-2"><i class="fa-solid fa-stop"></i></span>
                Stop
            </button>
        </div>

        <!-- Transcript Area -->
        <div class="flex-1 bg-white rounded-2xl shadow-sm border border-gray-200 overflow-hidden flex flex-col relative">
            
            <!-- Toolbar -->
            <div class="px-4 py-2 border-b border-gray-100 flex justify-between items-center bg-gray-50">
                <span class="text-xs font-semibold text-gray-500 uppercase tracking-wide">Live Transcript</span>
                <button id="btn-clear" class="text-xs text-red-500 hover:text-red-700">Clear History</button>
            </div>

            <!-- Content -->
            <div id="transcript-container" class="flex-1 overflow-y-auto p-6 space-y-4 scroll-smooth">
                <div class="text-center text-gray-400 mt-10 italic" id="empty-state">
                    <i class="fa-solid fa-wave-square text-4xl mb-3 opacity-30"></i>
                    <p>Waiting for audio...</p>
                    <p class="text-sm mt-2">Click Start, then select the tab/window playing audio.</p>
                    <p class="text-xs mt-1 text-yellow-600">Ensure "Share Audio" is checked in the browser prompt.</p>
                </div>
            </div>

            <!-- Live Preview Bar (The "Subtitle" look) -->
            <div class="bg-gray-900 text-white p-4 min-h-[80px] flex items-center justify-center text-center relative">
                <div class="absolute top-0 left-0 bg-blue-500 text-[10px] px-2 py-0.5 font-bold uppercase rounded-br">Live</div>
                <p id="live-subtitle" class="text-lg font-medium leading-relaxed transition-all duration-200">
                    ...
                </p>
            </div>
        </div>
    </main>

    <!-- Settings Modal -->
    <div id="settings-modal" class="fixed inset-0 z-40 bg-black/20 backdrop-blur-sm hidden flex items-center justify-center">
        <div class="bg-white rounded-xl shadow-2xl p-6 w-80 transform transition-all">
            <div class="flex justify-between items-center mb-4">
                <h3 class="font-bold text-gray-800">Subtitle Settings</h3>
                <button id="close-settings" class="text-gray-400 hover:text-gray-600"><i class="fa-solid fa-times"></i></button>
            </div>
            
            <div class="space-y-4">
                <div>
                    <label class="block text-xs font-semibold text-gray-500 mb-1">Font Size</label>
                    <input type="range" id="setting-size" min="16" max="48" value="24" class="w-full accent-blue-600">
                    <div class="flex justify-between text-xs text-gray-400"><span>Small</span><span>Large</span></div>
                </div>

                <div>
                    <label class="block text-xs font-semibold text-gray-500 mb-1">Text Color</label>
                    <div class="flex gap-2">
                        <button class="w-8 h-8 rounded-full bg-white border border-gray-300 ring-2 ring-transparent hover:ring-blue-400 focus:ring-blue-600" data-color="#FFFFFF"></button>
                        <button class="w-8 h-8 rounded-full bg-yellow-300 border border-gray-300 ring-2 ring-transparent hover:ring-blue-400 focus:ring-blue-600" data-color="#FDE047"></button>
                        <button class="w-8 h-8 rounded-full bg-green-300 border border-gray-300 ring-2 ring-transparent hover:ring-blue-400 focus:ring-blue-600" data-color="#86EFAC"></button>
                        <button class="w-8 h-8 rounded-full bg-black border border-gray-300 ring-2 ring-transparent hover:ring-blue-400 focus:ring-blue-600" data-color="#000000"></button>
                    </div>
                </div>

                <div>
                    <label class="block text-xs font-semibold text-gray-500 mb-1">Background Opacity</label>
                    <input type="range" id="setting-bg-opacity" min="0" max="1" step="0.1" value="0.7" class="w-full accent-blue-600">
                </div>
            </div>
        </div>
    </div>

    <!-- Hidden Video Element for PiP Magic -->
    <video id="pip-video" class="fixed pointer-events-none opacity-0 top-0 left-0" autoplay muted playsinline width="600" height="200"></video>
    <canvas id="pip-canvas" width="600" height="200" class="hidden"></canvas>

    <script type="module">
        import { GoogleGenerativeAI } from "https://esm.run/@google/generative-ai";

        // --- State Management ---
        const state = {
            apiKey: localStorage.getItem('gemini_api_key') || '',
            isRecording: false,
            mediaRecorder: null,
            audioContext: null,
            stream: null,
            subtitleSettings: {
                fontSize: 24,
                color: '#FFFFFF',
                bgOpacity: 0.7,
                fontFamily: 'Inter, sans-serif'
            },
            currentSubtitle: "",
            history: []
        };

        // --- DOM Elements ---
        const els = {
            apiKeyModal: document.getElementById('api-key-modal'),
            apiKeyInput: document.getElementById('api-key-input'),
            btnSaveKey: document.getElementById('btn-save-key'),
            btnStart: document.getElementById('btn-start'),
            btnStop: document.getElementById('btn-stop'),
            btnPip: document.getElementById('btn-pip'),
            btnSettings: document.getElementById('btn-settings'),
            settingsModal: document.getElementById('settings-modal'),
            closeSettings: document.getElementById('close-settings'),
            liveSubtitle: document.getElementById('live-subtitle'),
            transcriptContainer: document.getElementById('transcript-container'),
            emptyState: document.getElementById('empty-state'),
            statusBadge: document.getElementById('status-badge'),
            pipVideo: document.getElementById('pip-video'),
            pipCanvas: document.getElementById('pip-canvas'),
            btnClear: document.getElementById('btn-clear'),
            // Settings Inputs
            settingSize: document.getElementById('setting-size'),
            settingBgOpacity: document.getElementById('setting-bg-opacity'),
            colorButtons: document.querySelectorAll('[data-color]')
        };

        // --- Initialization ---
        if (state.apiKey) {
            els.apiKeyModal.classList.add('hidden');
        }

        els.btnSaveKey.addEventListener('click', () => {
            const key = els.apiKeyInput.value.trim();
            if (key.length > 10) {
                state.apiKey = key;
                localStorage.setItem('gemini_api_key', key);
                els.apiKeyModal.classList.add('hidden');
            } else {
                alert("Please enter a valid API Key");
            }
        });

        // --- Core Audio Logic ---

        async function startCapture() {
            try {
                setStatus('setup', 'Select Tab & Share Audio');

                // 1. Capture System Audio (Display Media)
                // NOTE: User MUST check "Share Audio" in the browser prompt
                const displayStream = await navigator.mediaDevices.getDisplayMedia({
                    video: true, // Required to get the prompt, we will ignore the video track
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 44100
                    }
                });

                // Check if audio track exists (User might have forgotten to check the box)
                if (displayStream.getAudioTracks().length === 0) {
                    alert("No system audio detected. Please ensure you check 'Share Audio' in the screen sharing prompt.");
                    displayStream.getTracks().forEach(track => track.stop());
                    setStatus('ready', 'Ready');
                    return;
                }

                // 2. Capture Microphone
                const micStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true
                    }
                });

                // 3. Mix Streams using Web Audio API
                state.audioContext = new AudioContext();
                const dest = state.audioContext.createMediaStreamDestination();

                const sysSource = state.audioContext.createMediaStreamSource(displayStream);
                const micSource = state.audioContext.createMediaStreamSource(micStream);
                
                // Gain nodes to balance levels if needed
                const sysGain = state.audioContext.createGain();
                const micGain = state.audioContext.createGain();
                sysGain.gain.value = 1.0; 
                micGain.gain.value = 1.0; // Microphone volume

                sysSource.connect(sysGain).connect(dest);
                micSource.connect(micGain).connect(dest);

                // 4. Setup Recorder
                state.stream = dest.stream;
                
                // Use a MIME type supported by Gemini (audio/wav or audio/mp3 usually preferred for generic usage, but raw PCM or webm is what browsers give)
                // Gemini supports: WAV, MP3, AAC, FLAC, OGG. Browser MediaRecorder usually outputs WebM/Opus.
                const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus') ? 'audio/webm;codecs=opus' : 'audio/webm';
                
                state.mediaRecorder = new MediaRecorder(state.stream, { mimeType: mimeType });
                
                state.mediaRecorder.ondataavailable = async (e) => {
                    if (e.data.size > 0 && state.isRecording) {
                        processAudioChunk(e.data);
                    }
                };

                // Chunk every 3 seconds for "Live" feel. 
                // Smaller chunks = faster updates but context cut-off risk.
                // Larger chunks = better accuracy but higher latency.
                // 2500ms is a sweet spot for "Live" translation.
                state.mediaRecorder.start(3000); 

                state.isRecording = true;
                updateUiState(true);
                setStatus('recording', 'Listening...');

                // Handle stop (e.g. if user clicks "Stop Sharing" on browser UI)
                displayStream.getVideoTracks()[0].onended = stopCapture;

            } catch (err) {
                console.error("Capture Error:", err);
                alert("Could not start capture: " + err.message);
                setStatus('ready', 'Ready');
            }
        }

        function stopCapture() {
            if (!state.isRecording) return;

            state.isRecording = false;
            state.mediaRecorder.stop();
            state.stream.getTracks().forEach(track => track.stop());
            if (state.audioContext) state.audioContext.close();

            updateUiState(false);
            setStatus('ready', 'Stopped');
        }

        // --- Gemini Integration ---

        async function processAudioChunk(blob) {
            // Show loading state on subtitle
            renderSubtitle(state.currentSubtitle, true);

            try {
                const genAI = new GoogleGenerativeAI(state.apiKey);
                const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });

                // Convert Blob to Base64
                const base64Data = await blobToBase64(blob);

                // Prompt Engineering for Live Translation
                const prompt = `
                    You are a simultaneous interpreter. 
                    The audio contains Korean speech (and possibly English).
                    Your task:
                    1. Transcribe the Korean speech.
                    2. Translate it into natural, concise English.
                    3. If the audio is silence, music, or noise, return "SILENCE".
                    4. If the audio is English only, transcribe it.
                    5. Output ONLY the English translation. Do not explain.
                `;

                const result = await model.generateContent([
                    prompt,
                    {
                        inlineData: {
                            mimeType: "audio/webm", // Or the mime type used by MediaRecorder
                            data: base64Data
                        }
                    }
                ]);

                const response = result.response;
                const text = response.text().trim();

                if (text && text !== "SILENCE" && !text.includes("SILENCE")) {
                    updateTranscript(text);
                } else {
                    renderSubtitle(state.currentSubtitle, false); // Remove loading indicator
                }

            } catch (error) {
                console.error("Gemini API Error:", error);
                // Don't alert on every error, just log. 429 (Too Many Requests) is common with aggressive chunking.
                if (error.message.includes('429')) {
                   // console.warn("Rate limited - backing off");
                }
            }
        }

        function blobToBase64(blob) {
            return new Promise((resolve, _) => {
                const reader = new FileReader();
                reader.onloadend = () => resolve(reader.result.split(',')[1]);
                reader.readAsDataURL(blob);
            });
        }

        // --- UI & Rendering Logic ---

        function updateTranscript(newText) {
            state.currentSubtitle = newText;
            
            // Add to history
            const item = document.createElement('div');
            item.className = "p-3 rounded-lg bg-gray-50 border border-gray-100 animate-fade-in";
            item.innerHTML = `<p class="text-gray-800 font-medium">${newText}</p>`;
            
            els.emptyState.style.display = 'none';
            els.transcriptContainer.appendChild(item);
            els.transcriptContainer.scrollTop = els.transcriptContainer.scrollHeight;

            // Render to Live Box and Canvas
            renderSubtitle(newText, false);
        }

        function updateUiState(isRecording) {
            if (isRecording) {
                els.btnStart.classList.add('hidden');
                els.btnStop.classList.remove('hidden');
            } else {
                els.btnStart.classList.remove('hidden');
                els.btnStop.classList.add('hidden');
            }
        }

        function setStatus(type, text) {
            const colors = {
                ready: 'bg-gray-400',
                setup: 'bg-yellow-400',
                recording: 'bg-red-500 animate-pulse'
            };
            const badgeColor = colors[type] || 'bg-gray-400';
            
            els.statusBadge.innerHTML = `
                <div class="w-2 h-2 rounded-full ${badgeColor}"></div>
                ${text}
            `;
        }

        // --- Picture-in-Picture (PiP) Subtitle Engine ---

        const ctx = els.pipCanvas.getContext('2d');

        function renderSubtitle(text, isLoading) {
            // Update on-screen HTML element
            els.liveSubtitle.textContent = text + (isLoading ? " •" : "");
            
            // Update Canvas for PiP
            const w = els.pipCanvas.width;
            const h = els.pipCanvas.height;
            const s = state.subtitleSettings;

            // Clear
            ctx.clearRect(0, 0, w, h);

            // Background
            ctx.fillStyle = hexToRgba('#000000', s.bgOpacity); // Black background usually reads best for subtitles
            ctx.fillRect(0, 0, w, h);

            // Text configuration
            ctx.font = `bold ${s.fontSize}px ${s.fontFamily}`;
            ctx.fillStyle = s.color;
            ctx.textAlign = "center";
            ctx.textBaseline = "middle";

            // Word wrap logic for canvas
            const maxWidth = w - 40;
            const words = text.split(' ');
            let line = '';
            let lines = [];
            
            for(let n = 0; n < words.length; n++) {
                const testLine = line + words[n] + ' ';
                const metrics = ctx.measureText(testLine);
                const testWidth = metrics.width;
                if (testWidth > maxWidth && n > 0) {
                    lines.push(line);
                    line = words[n] + ' ';
                } else {
                    line = testLine;
                }
            }
            lines.push(line);

            // Draw lines
            const lineHeight = s.fontSize * 1.4;
            const startY = (h - (lines.length * lineHeight)) / 2 + (lineHeight/2);

            lines.forEach((l, i) => {
                ctx.fillText(l, w/2, startY + (i * lineHeight));
            });

            // Loading indicator
            if (isLoading) {
                ctx.fillStyle = "#3B82F6";
                ctx.beginPath();
                ctx.arc(w - 20, 20, 5, 0, 2 * Math.PI);
                ctx.fill();
            }
        }

        // Toggle PiP
        els.btnPip.addEventListener('click', async () => {
            // 1. Setup the stream from canvas
            if (els.pipVideo.readyState === 0) {
                const stream = els.pipCanvas.captureStream(30); // 30 FPS
                els.pipVideo.srcObject = stream;
                // Need to play it for PiP to work
                await els.pipVideo.play();
            }

            // 2. Request PiP
            try {
                if (document.pictureInPictureElement) {
                    await document.exitPictureInPicture();
                } else {
                    await els.pipVideo.requestPictureInPicture();
                }
            } catch(e) {
                alert("Picture-in-Picture failed: " + e.message);
            }
        });

        // --- Settings Logic ---
        els.btnSettings.addEventListener('click', () => els.settingsModal.classList.remove('hidden'));
        els.closeSettings.addEventListener('click', () => els.settingsModal.classList.add('hidden'));

        els.settingSize.addEventListener('input', (e) => {
            state.subtitleSettings.fontSize = parseInt(e.target.value);
            renderSubtitle(state.currentSubtitle, false);
        });
        
        els.settingBgOpacity.addEventListener('input', (e) => {
            state.subtitleSettings.bgOpacity = parseFloat(e.target.value);
            renderSubtitle(state.currentSubtitle, false);
        });

        els.colorButtons.forEach(btn => {
            btn.addEventListener('click', () => {
                state.subtitleSettings.color = btn.dataset.color;
                // visual selection feedback
                els.colorButtons.forEach(b => b.classList.remove('ring-offset-2', 'ring-2', 'ring-blue-500'));
                btn.classList.add('ring-offset-2', 'ring-2', 'ring-blue-500');
                renderSubtitle(state.currentSubtitle, false);
            });
        });

        els.btnClear.addEventListener('click', () => {
            els.transcriptContainer.innerHTML = '';
            els.transcriptContainer.appendChild(els.emptyState);
            els.emptyState.style.display = 'block';
        });

        // Helper
        function hexToRgba(hex, alpha) {
            const r = parseInt(hex.slice(1, 3), 16);
            const g = parseInt(hex.slice(3, 5), 16);
            const b = parseInt(hex.slice(5, 7), 16);
            return `rgba(${r}, ${g}, ${b}, ${alpha})`;
        }

        // Event Listeners for main buttons
        els.btnStart.addEventListener('click', startCapture);
        els.btnStop.addEventListener('click', stopCapture);

        // Initial Render
        renderSubtitle("Subtitles will appear here...", false);

    </script>
</body>
</html>
